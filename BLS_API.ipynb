{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API limitations:\n",
    " - 50 series allowed per pull\n",
    " - 20 years allowed per pull\n",
    " - approx 5000 PPI series with some series having data starting in the 1960s means approx 300 pulls required - 100 for all series, * 3 for 20 year selections out to the 60s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from bls_definitions import bls_ppi_codes\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"9648e84bbf0f4c38b01689279269a05e\"\n",
    "url = \"https://api.bls.gov/publicAPI/v2/timeseries/data/\"\n",
    "startyear = \"2004\"\n",
    "endyear = \"2023\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_dict = {\"seriesid\": ['WPUFD4'], \"startyear\":startyear, \"endyear\":endyear, \"registrationkey\" : key}\n",
    "selection = json.dumps(selection_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'Content-type' : 'application/json'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = requests.post('https://api.bls.gov/publicAPI/v2/timeseries/data/', data=selection, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = p.json()['Results']['series']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_list = [f\"{i['year']}-{i['period'][1:]}-01\" for i in p[0]['data']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(index = pd.to_datetime(date_list[::-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in p:\n",
    "    df[i['seriesID']] = pd.Series([j['value'] for j in i['data']]).astype(float).iloc[::-1].values\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempt with first 50 codes from bls list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = list(bls_ppi_codes.keys())[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_dict = {\"seriesid\": codes, \"startyear\":startyear, \"endyear\":endyear, \"registrationkey\" : key}\n",
    "selection = json.dumps(selection_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = requests.post('https://api.bls.gov/publicAPI/v2/timeseries/data/', data=selection, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = p.json()['Results']['series']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame()\n",
    "data = {}\n",
    "index = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in p:\n",
    "    data[i['seriesID']] = pd.Series([j['value'] for j in i['data']]).astype(float).iloc[::-1].values\n",
    "    index[i['seriesID']] = [f\"{j['year']}-{j['period'][1:]}-01\" for j in i['data']][::-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_codes = []\n",
    "for i in p:\n",
    "    if len(i['data']) == 0:\n",
    "        missing_codes.append(i['seriesID'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {}\n",
    "for i in data.keys():\n",
    "    dfs[i] = pd.DataFrame(data = data[i], index = pd.to_datetime(index[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.concat(dfs,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.columns = final.columns.get_level_values(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "50 codes over three 20 year windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endyear = datetime.datetime.now().year\n",
    "\n",
    "date_ranges = {0 : (endyear-19, endyear),\n",
    "               1 : (endyear-39, endyear-20),\n",
    "               2 : (endyear-59, endyear-40)}\n",
    "\n",
    "codes = list(bls_ppi_codes.keys())[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_diff_periods = {}\n",
    "missing_series = {}\n",
    "\n",
    "for i in date_ranges:\n",
    "    # create variable selection dictionary\n",
    "    selection_dict = {\"seriesid\": codes, \"startyear\":date_ranges[i][0], \"endyear\":date_ranges[i][1], \"registrationkey\" : key}\n",
    "    selection = json.dumps(selection_dict)\n",
    "    \n",
    "    # send request to BLS\n",
    "    p = requests.post('https://api.bls.gov/publicAPI/v2/timeseries/data/', data=selection, headers=headers)\n",
    "    p = p.json()['Results']['series']\n",
    "    \n",
    "    # create dictionaries to hold values and index\n",
    "    data = {}\n",
    "    index = {}\n",
    "    \n",
    "    # save time series and index for each variable\n",
    "    for j in p:\n",
    "        data[j['seriesID']] = pd.Series([k['value'] for k in j['data']]).astype(float).iloc[::-1].values\n",
    "        index[j['seriesID']] = [f\"{k['year']}-{k['period'][1:]}-01\" for k in j['data']][::-1]\n",
    "    \n",
    "    # identify where codes are missing in each period window\n",
    "    missing_codes = []\n",
    "    for j in p:\n",
    "        if len(j['data']) == 0:\n",
    "            missing_codes.append(j['seriesID'])\n",
    "    missing_series[i] = missing_codes\n",
    "\n",
    "    # convert series into dataframes and then combine into one dataframe for the period window\n",
    "    dfs = {}\n",
    "    for j in data.keys():\n",
    "        dfs[j] = pd.DataFrame(data = data[j], index = pd.to_datetime(index[j]))\n",
    "\n",
    "    final = pd.concat(dfs,axis=1)\n",
    "    final.columns = final.columns.get_level_values(0)\n",
    "\n",
    "    dfs_diff_periods[i] = final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.concat(dfs_diff_periods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.index = full_df.index.droplevel(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = full_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_sets = {}\n",
    "for i in missing_series.keys():\n",
    "    missing_sets[i] = set(missing_series[i])\n",
    "\n",
    "variables_no_data = missing_sets[0].intersection(missing_sets[1]).intersection(missing_sets[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_no_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looping all codes in sets of 50 over three 20 year periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create date ranges to loop on\n",
    "endyear = datetime.datetime.now().year\n",
    "\n",
    "date_ranges = {0 : (endyear-19, endyear),\n",
    "               1 : (endyear-39, endyear-20),\n",
    "               2 : (endyear-59, endyear-40)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bls_ppi_code_segments = [list(bls_ppi_codes.keys())[x:x+50]for x in range(0, len(list(bls_ppi_codes.keys())), 50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_dfs = {}\n",
    "master_missing_series = {}\n",
    "segment_no = 0\n",
    "\n",
    "# loop over sets of 50 codes\n",
    "for i in bls_ppi_code_segments:\n",
    "    dfs_diff_periods = {}\n",
    "    missing_series = {}\n",
    "    for j in date_ranges:\n",
    "        # create variatble selection dictionary\n",
    "        selection_dict = {\"seriesid\": i, \"startyear\":date_ranges[j][0], \"endyear\":date_ranges[j][1], \"registrationkey\" : key}\n",
    "        selection = json.dumps(selection_dict)\n",
    "\n",
    "        # send request to BLS\n",
    "        p = requests.post('https://api.bls.gov/publicAPI/v2/timeseries/data/', data=selection, headers=headers)\n",
    "        p = p.json()['Results']['series']\n",
    "\n",
    "        # create dictionaries to hold values and index\n",
    "        data = {}\n",
    "        index = {}\n",
    "\n",
    "        # save time series and index for each variable\n",
    "        for k in p:\n",
    "            data[k['seriesID']] = pd.Series([l['value'] for l in k['data']]).astype(float).iloc[::-1].values\n",
    "            index[k['seriesID']] = [f\"{l['year']}-{l['period'][1:]}-01\" for l in k['data']][::-1]\n",
    "\n",
    "        # identify where codes are missing in each period window\n",
    "        missing_codes = []\n",
    "        for k in p:\n",
    "            if len(k['data']) == 0:\n",
    "                missing_codes.append(k['seriesID'])\n",
    "        missing_series[j] = missing_codes\n",
    "\n",
    "        # convert series into dataframes and then combine into one dataframe for the period window\n",
    "        dfs = {}\n",
    "        for k in data.keys():\n",
    "            dfs[k] = pd.DataFrame(data = data[k], index = pd.to_datetime(index[k]))\n",
    "\n",
    "        final = pd.concat(dfs,axis=1)\n",
    "        final.columns = final.columns.get_level_values(0)\n",
    "\n",
    "        dfs_diff_periods[j] = final\n",
    "    \n",
    "    # combine dfs of series into one dataframe\n",
    "    segment_df = pd.concat(dfs_diff_periods)\n",
    "    segment_df.index = segment_df.index.droplevel(0)\n",
    "    segment_df = segment_df.sort_index()\n",
    "    \n",
    "    # save segment df to master dictionary\n",
    "    master_dfs[segment_no] = segment_df\n",
    "\n",
    "    # identify codes with no values across all periods\n",
    "    missing_sets = {}\n",
    "    for j in missing_series.keys():\n",
    "        missing_sets[j] = set(missing_series[j])\n",
    "\n",
    "    variables_no_data = missing_sets[0].intersection(missing_sets[1]).intersection(missing_sets[2])\n",
    "\n",
    "    master_missing_series[segment_no] = variables_no_data\n",
    "\n",
    "    print(segment_no)\n",
    "    segment_no += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # merge master dataframes into \n",
    "# all_ppi = pd.concat(master_dfs)\n",
    "# all_ppi.index = all_ppi.index.droplevel(0)\n",
    "# all_ppi = all_ppi.sort_index()\n",
    "\n",
    "# # remove duplicate index values\n",
    "# all_ppi = all_ppi[~all_ppi.index.duplicated(keep='first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_ppi.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 14.5 TiB for an array with shape (1995926400001,) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\PETERC~1\\AppData\\Local\\Temp/ipykernel_14116/1124477968.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mall_ppi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate_range\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'1/1/1960'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmonth\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/1/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myear\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ms'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Peter Colson\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\datetimes.py\u001b[0m in \u001b[0;36mdate_range\u001b[1;34m(start, end, periods, freq, tz, normalize, name, closed, **kwargs)\u001b[0m\n\u001b[0;32m   1095\u001b[0m         \u001b[0mfreq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"D\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1096\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1097\u001b[1;33m     dtarr = DatetimeArray._generate_range(\n\u001b[0m\u001b[0;32m   1098\u001b[0m         \u001b[0mstart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m         \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Peter Colson\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arrays\\datetimes.py\u001b[0m in \u001b[0;36m_generate_range\u001b[1;34m(cls, start, end, periods, freq, tz, normalize, ambiguous, nonexistent, closed)\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTick\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 442\u001b[1;33m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_regular_range\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mperiods\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    443\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m                 \u001b[0mxdr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_range\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mperiods\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mperiods\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Peter Colson\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arrays\\_ranges.py\u001b[0m in \u001b[0;36mgenerate_regular_range\u001b[1;34m(start, end, periods, freq)\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[1;31m#  and incorrectly return an empty array if not caught.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mFloatingPointError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[0mxdr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 14.5 TiB for an array with shape (1995926400001,) and data type int64"
     ]
    }
   ],
   "source": [
    "all_ppi = pd.DataFrame(index=pd.date_range(start='1/1/1960', end =  str(datetime.datetime.now().month) + '/1/' + str(datetime.datetime.now().year), freq='ms'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in master_dfs.keys():\n",
    "    for j in master_dfs[i].columns:\n",
    "        all_ppi[j] = master_dfs[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ppi.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ppi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
