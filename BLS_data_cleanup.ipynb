{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert API pulls to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bls_dfs = {}\n",
    "\n",
    "for i in range(0,100):\n",
    "    bls_dfs[i] = pd.read_parquet('C:\\\\DSWG_PPI\\\\api_pulls\\\\'+str(i)+'api.gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ppi = pd.DataFrame(index=pd.date_range(start='1/1/1960', end =  str(datetime.datetime.now().month) + '/1/' + str(datetime.datetime.now().year), freq='MS'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PETERC~1\\AppData\\Local\\Temp/ipykernel_17508/2348812516.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  all_ppi[j] = bls_dfs[i][j]\n"
     ]
    }
   ],
   "source": [
    "for i in bls_dfs.keys():\n",
    "    for j in bls_dfs[i].columns:\n",
    "        all_ppi[j] = bls_dfs[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ppi_q = all_ppi.resample('Q').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ppi_q.to_csv('all_ppi_q.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove series with no data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppi_no_data = list(all_ppi_q.loc[:,all_ppi_q.isna().all()].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove series with no data\n",
    "ppi_clean = all_ppi_q.loc[:,~all_ppi_q.isna().all()]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate endpoints to identify discontinued series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoints = {}\n",
    "for i in ppi_clean.columns:\n",
    "    endpoints[i] = ppi_clean[i].last_valid_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(endpoints).to_csv('endpoints.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count each instance of the endpoint dates\n",
    "endpoints_count = {}\n",
    "\n",
    "for i in endpoints.values():\n",
    "    # Timestamp formatted to string and time removed\n",
    "    i = str(i).split(\" \")[0]\n",
    "    if i not in endpoints_count.keys():\n",
    "        endpoints_count[i] = 1\n",
    "    else:\n",
    "        endpoints_count[i] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the series into lists by endpoint\n",
    "endpoints_list = {}\n",
    "\n",
    "for i in endpoints.keys():\n",
    "    # Timestamp formatted to string and time removed\n",
    "    date = str(endpoints[i]).split(\" \")[0]\n",
    "    if date not in endpoints_list.keys():\n",
    "        endpoints_list[date] = [i]\n",
    "    else:\n",
    "        endpoints_list[date].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check there are no differences between list and count dictionaries - will print eroneous series if so\n",
    "for i in endpoints_count.keys():\n",
    "    if len(endpoints_list[i]) != endpoints_count[i]:\n",
    "        print(i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove discontinued series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a cutoff value - anything prior to the start of the previous year?\n",
    "cutoff = str(datetime.datetime.now().year - 1) + '-01-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_cut = {}\n",
    "\n",
    "for i in endpoints_list.keys():\n",
    "    if i < cutoff:\n",
    "        to_cut[i] = endpoints_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in to_cut.keys():\n",
    "    ppi_clean = ppi_clean.drop(to_cut[i], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map codes to digit levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppi_codes =  pd.DataFrame(all_ppi_q.columns, columns=['START_CODE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove leading 'PCU' part of the code\n",
    "ppi_codes['CODE2'] = ppi_codes['START_CODE'].str.slice(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split codes including '-'\n",
    "ppi_codes['CODE3'] = ppi_codes['CODE2'].str.split('-').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify digit level\n",
    "ppi_codes['DIGIT'] = np.nan\n",
    "\n",
    "for i in ppi_codes.index:\n",
    "   if len(ppi_codes.loc[i, 'CODE3']) == 3:\n",
    "      ppi_codes.loc[i, 'DIGIT'] = 3\n",
    "   elif len(ppi_codes.loc[i, 'CODE3']) == 4:\n",
    "      ppi_codes.loc[i, 'DIGIT'] = 4\n",
    "   elif len(ppi_codes.loc[i, 'CODE3']) == 5:\n",
    "      ppi_codes.loc[i, 'DIGIT'] = 5\n",
    "   elif len(ppi_codes.loc[i, 'CODE3']) / 2 == 6:\n",
    "      ppi_codes.loc[i, 'DIGIT'] = 6\n",
    "   elif len(ppi_codes.loc[i, 'CODE3']) / 2 == 6.5:\n",
    "      ppi_codes.loc[i, 'DIGIT'] = 7\n",
    "   elif len(ppi_codes.loc[i, 'CODE3']) / 2 == 7:\n",
    "      ppi_codes.loc[i, 'DIGIT'] = 8\n",
    "   elif len(ppi_codes.loc[i, 'CODE3']) / 2 == 7.5:\n",
    "      ppi_codes.loc[i, 'DIGIT'] = 9\n",
    "   elif len(ppi_codes.loc[i, 'CODE3']) / 2 == 8:\n",
    "      ppi_codes.loc[i, 'DIGIT'] = 10\n",
    "   elif len(ppi_codes.loc[i, 'CODE3']) / 2 == 8.5:\n",
    "      ppi_codes.loc[i, 'DIGIT'] = 11\n",
    "   elif len(ppi_codes.loc[i, 'CODE3']) / 2 == 9:\n",
    "      ppi_codes.loc[i, 'DIGIT'] = 12\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set aggregate series digit to 'AGG'\n",
    "aggs = ['PCUAMUM--AMUM--', 'PCUOMIN--OMIN--', 'PCUOMFG--OMFG--', 'PCUATRADEATRADE', 'PCUAWHLTRAWHLTR', 'PCUARETTRARETTR', 'PCUATRNWRATRNWR', 'PCUATRANSATRANS', 'PCUADLVWRADLVWR', 'PCUATTDSVATTDSV', 'PCUAINFO-AINFO-', 'PCUASHC--ASHC--', 'PCUASTDSVASTDSV']\n",
    "\n",
    "for i in aggs:\n",
    "    ppi_codes.loc[ppi_codes['START_CODE'] == i, 'DIGIT'] = 'AGG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes_by_digit = {}\n",
    "\n",
    "for i in ppi_codes['DIGIT'].unique():\n",
    "    codes_by_digit[i] = list(ppi_codes[ppi_codes['DIGIT'] == i]['START_CODE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes_by_digit_clean = {}\n",
    "\n",
    "for i in ppi_codes['DIGIT'].unique():\n",
    "    codes_by_digit_clean[i] = []\n",
    "    for j in ppi_clean.columns:\n",
    "        if j in ppi_codes[ppi_codes['DIGIT'] == i]['START_CODE'].values:\n",
    "            codes_by_digit_clean[i].append(j)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort PPI dataframe into multi digit sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all series\n",
    "all_digit_dfs = {}\n",
    "\n",
    "for i in codes_by_digit.keys():\n",
    "    all_digit_dfs[i] = all_ppi_q[codes_by_digit[i]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a excel writer object\n",
    "with pd.ExcelWriter(\"C:\\\\DSWG_PPI\\\\all_ppi_q_by_digit.xlsx\") as writer:\n",
    "   for i in all_digit_dfs.keys():\n",
    "      all_digit_dfs[i].to_excel(writer, sheet_name=str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean series\n",
    "all_digit_dfs_clean = {}\n",
    "\n",
    "for i in codes_by_digit_clean.keys():\n",
    "    all_digit_dfs_clean[i] = ppi_clean[codes_by_digit_clean[i]]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Parent-Child Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_child_matrices = {}\n",
    "\n",
    "for i in range(4,13):\n",
    "    # start with 4 digit (3 digit series are all headlines by definition)\n",
    "    if i == 4:\n",
    "        # create matrix df with index of all digit level codes\n",
    "        matrix = pd.DataFrame(columns = ppi_codes['START_CODE'], index = all_digit_dfs[i].columns)\n",
    "\n",
    "        for j in matrix.index:\n",
    "            parents = [col for col in ppi_codes[ppi_codes['DIGIT'] == (i-1)]['START_CODE'] if j[3:(3+i-1)] in col[3:(3+i-1)]]\n",
    "            matrix.loc[j, parents] = 1\n",
    "\n",
    "        parent_child_matrices[i] = matrix\n",
    "    #5 to 7 digit level\n",
    "    elif i < 8:\n",
    "        # create matrix df with index of all digit level codes\n",
    "        matrix = pd.DataFrame(columns = ppi_codes['START_CODE'], index = all_digit_dfs[i].columns)\n",
    "        for j in matrix.index:\n",
    "            k = i \n",
    "            parents = [col for col in ppi_codes[ppi_codes['DIGIT'] == (k-1)]['START_CODE'] if j[3:(3+k-1)] in col[3:(3+k-1)]]\n",
    "            # while loop entered if parent in immediate digit level down is not found. Will then check the next level\n",
    "            # i.e. if 5 digit level code does not find a parent in the 4 digit level, then the 3 digit level is checked\n",
    "            # if no parent found, nothing is assigned and code assumed to be at the highest level available\n",
    "            while len(parents)==0 and k>4:\n",
    "                k = k-1\n",
    "                parents = [col for col in ppi_codes[ppi_codes['DIGIT'] == (k-1)]['START_CODE'] if j[3:(3+k-1)] in col[3:(3+k-1)]]\n",
    "            matrix.loc[j, parents] = 1\n",
    "\n",
    "        parent_child_matrices[i] = matrix\n",
    "    #8 and beyond digit level - focus needs to be on the product codes\n",
    "    else:\n",
    "        # create matrix df with index of all digit level codes\n",
    "        matrix = pd.DataFrame(columns = ppi_codes['START_CODE'], index = all_digit_dfs[i].columns)\n",
    "        for j in matrix.index:\n",
    "            k = i\n",
    "            parents = [col for col in ppi_codes[ppi_codes['DIGIT'] == (k-1)]['START_CODE'] if j[9:(9+k-1)] in col[9:(9+k-1)]]\n",
    "            while len(parents)==0 and k>4:\n",
    "                k = k-1\n",
    "                if k < 8:\n",
    "                    parents = [col for col in ppi_codes[ppi_codes['DIGIT'] == (k-1)]['START_CODE'] if j[3:(3+k-1)] in col[3:(3+k-1)]]\n",
    "                else:\n",
    "                    parents = [col for col in ppi_codes[ppi_codes['DIGIT'] == (k-1)]['START_CODE'] if j[9:(9+k-1)] in col[9:(9+k-1)]]\n",
    "            matrix.loc[j, parents] = 1\n",
    "        parent_child_matrices[i] = matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in parent_child_matrices.keys():\n",
    "    parent_child_matrices[i]['sum'] = parent_child_matrices[i].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a excel writer object\n",
    "with pd.ExcelWriter(\"C:\\\\DSWG_PPI\\\\parent_child_matrices.xlsx\") as writer:\n",
    "   for i in parent_child_matrices.keys():\n",
    "      parent_child_matrices[i].to_excel(writer, sheet_name=str(i))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify series with breaks in the time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_time_series_all = {}\n",
    "# loop over digit level\n",
    "for i in all_digit_dfs.keys():\n",
    "    missing_time_series_all[i] = []\n",
    "    # loop over codes at each level\n",
    "    for j in all_digit_dfs[i].columns:\n",
    "        # if any nan values between the first and last datapoints there are missing values, append to list\n",
    "        if all_digit_dfs[i].loc[all_digit_dfs[i][j].first_valid_index():all_digit_dfs[i][j].last_valid_index(),j].isna().any():\n",
    "            missing_time_series_all[i].append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_time_series_clean = {}\n",
    "# loop over digit level\n",
    "for i in all_digit_dfs_clean.keys():\n",
    "    missing_time_series_clean[i] = []\n",
    "    # loop over codes at each level\n",
    "    for j in all_digit_dfs_clean[i].columns:\n",
    "        # if any nan values between the first and last datapoints there are missing values, append to list\n",
    "        if all_digit_dfs_clean[i].loc[all_digit_dfs_clean[i][j].first_valid_index():all_digit_dfs_clean[i][j].last_valid_index(),j].isna().any():\n",
    "            missing_time_series_clean[i].append(j)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill missing series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Peter Colson\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:1951: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[selected_item_labels] = value\n"
     ]
    }
   ],
   "source": [
    "for i in all_digit_dfs_clean.keys():\n",
    "    for j in missing_time_series_clean[i]:\n",
    "        all_digit_dfs_clean[i].loc[:,j] = all_digit_dfs_clean[i].loc[:,j].interpolate(method='linear', limit_area = 'inside') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a excel writer object\n",
    "with pd.ExcelWriter(\"C:\\\\DSWG_PPI\\\\clean_ppi_q_by_digit.xlsx\") as writer:\n",
    "   for i in all_digit_dfs_clean.keys():\n",
    "      all_digit_dfs_clean[i].to_excel(writer, sheet_name=str(i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
